Hello from compute69.bgsc.cluster
Done with train
Subject: 1
              precision    recall  f1-score   support

           0     0.9646    0.9924    0.9783      5137
           1     0.9922    0.9636    0.9777      5137

    accuracy                         0.9780     10274
   macro avg     0.9784    0.9780    0.9780     10274
weighted avg     0.9784    0.9780    0.9780     10274

0.0075919797547206545
tn:5098 fp:39 fn:187 tp:4950
auc: 0.9780027253260658
alt auc: 0.9969108638603037
FPR: 0.0075919797547206545
FNR: 0.03640256959314775
Subject: 2
              precision    recall  f1-score   support

           0     0.8514    0.9861    0.9138      4240
           1     0.9835    0.8278    0.8990      4240

    accuracy                         0.9070      8480
   macro avg     0.9174    0.9070    0.9064      8480
weighted avg     0.9174    0.9070    0.9064      8480

0.013915094339622642
tn:4181 fp:59 fn:730 tp:3510
auc: 0.9069575471698113
alt auc: 0.9823041173460306
FPR: 0.013915094339622642
FNR: 0.1721698113207547
Subject: 3
              precision    recall  f1-score   support

           0     0.8620    0.9802    0.9173      8246
           1     0.9771    0.8431    0.9051      8246

    accuracy                         0.9117     16492
   macro avg     0.9195    0.9117    0.9112     16492
weighted avg     0.9195    0.9117    0.9112     16492

0.01976715983507155
tn:8083 fp:163 fn:1294 tp:6952
auc: 0.9116541353383458
alt auc: 0.9802758938413845
FPR: 0.01976715983507155
FNR: 0.15692456948823671
Subject: 4
              precision    recall  f1-score   support

           0     0.8529    0.9883    0.9156      6582
           1     0.9861    0.8295    0.9011      6582

    accuracy                         0.9089     13164
   macro avg     0.9195    0.9089    0.9083     13164
weighted avg     0.9195    0.9089    0.9083     13164

0.011698571862655728
tn:6505 fp:77 fn:1122 tp:5460
auc: 0.9089182619264661
alt auc: 0.9819478802856442
FPR: 0.011698571862655728
FNR: 0.17046490428441202
Subject: 5
              precision    recall  f1-score   support

           0     0.8491    0.9805    0.9101      5295
           1     0.9770    0.8257    0.8950      5295

    accuracy                         0.9031     10590
   macro avg     0.9130    0.9031    0.9025     10590
weighted avg     0.9130    0.9031    0.9025     10590

0.019452313503305004
tn:5192 fp:103 fn:923 tp:4372
auc: 0.9031161473087819
alt auc: 0.9815077027609027
FPR: 0.019452313503305004
FNR: 0.17431539187913125
Subject: 6
              precision    recall  f1-score   support

           0     0.8742    0.9767    0.9226      4893
           1     0.9736    0.8594    0.9129      4893

    accuracy                         0.9180      9786
   macro avg     0.9239    0.9180    0.9178      9786
weighted avg     0.9239    0.9180    0.9178      9786

0.023298589822194973
tn:4779 fp:114 fn:688 tp:4205
auc: 0.9180461884324546
alt auc: 0.9837317490683207
FPR: 0.023298589822194973
FNR: 0.14060903331289598
Subject: 7
              precision    recall  f1-score   support

           0     0.8402    0.9892    0.9086      7286
           1     0.9868    0.8118    0.8908      7286

    accuracy                         0.9005     14572
   macro avg     0.9135    0.9005    0.8997     14572
weighted avg     0.9135    0.9005    0.8997     14572

0.010842712050507823
tn:7207 fp:79 fn:1371 tp:5915
auc: 0.9004940982706561
alt auc: 0.980227064881913
FPR: 0.010842712050507823
FNR: 0.18816909140818008
Subject: 8
              precision    recall  f1-score   support

           0     0.8397    0.9857    0.9068      5935
           1     0.9827    0.8118    0.8891      5935

    accuracy                         0.8987     11870
   macro avg     0.9112    0.8987    0.8980     11870
weighted avg     0.9112    0.8987    0.8980     11870

0.014321819713563605
tn:5850 fp:85 fn:1117 tp:4818
auc: 0.8987363100252738
alt auc: 0.980173715674369
FPR: 0.014321819713563605
FNR: 0.1882055602358888
Subject: 9
              precision    recall  f1-score   support

           0     0.8690    0.9844    0.9231      5888
           1     0.9820    0.8516    0.9121      5888

    accuracy                         0.9180     11776
   macro avg     0.9255    0.9180    0.9176     11776
weighted avg     0.9255    0.9180    0.9176     11776

0.015625
tn:5796 fp:92 fn:874 tp:5014
auc: 0.91796875
alt auc: 0.9821132667123257
FPR: 0.015625
FNR: 0.1484375
Subject: 10
              precision    recall  f1-score   support

           0     0.8871    0.9889    0.9352      4614
           1     0.9875    0.8741    0.9273      4614

    accuracy                         0.9315      9228
   macro avg     0.9373    0.9315    0.9313      9228
weighted avg     0.9373    0.9315    0.9313      9228

0.011053315994798439
tn:4563 fp:51 fn:581 tp:4033
auc: 0.9315127871694843
alt auc: 0.9881075180811723
FPR: 0.011053315994798439
FNR: 0.1259211096662332
Subject: 11
              precision    recall  f1-score   support

           0     0.8374    0.9923    0.9083      4522
           1     0.9905    0.8074    0.8896      4522

    accuracy                         0.8998      9044
   macro avg     0.9140    0.8998    0.8990      9044
weighted avg     0.9140    0.8998    0.8990      9044

0.007739938080495356
tn:4487 fp:35 fn:871 tp:3651
auc: 0.8998230871295888
alt auc: 0.9823774466605936
FPR: 0.007739938080495356
FNR: 0.19261388766032728
Subject: 12
              precision    recall  f1-score   support

           0     0.9036    0.9791    0.9398      3828
           1     0.9772    0.8955    0.9346      3828

    accuracy                         0.9373      7656
   macro avg     0.9404    0.9373    0.9372      7656
weighted avg     0.9404    0.9373    0.9372      7656

0.02089864158829676
tn:3748 fp:80 fn:400 tp:3428
auc: 0.9373040752351097
alt auc: 0.987330403265167
FPR: 0.02089864158829676
FNR: 0.1044932079414838
Subject: 13
              precision    recall  f1-score   support

           0     0.8682    0.9873    0.9239      5602
           1     0.9853    0.8501    0.9127      5602

    accuracy                         0.9187     11204
   macro avg     0.9267    0.9187    0.9183     11204
weighted avg     0.9267    0.9187    0.9183     11204

0.01267404498393431
tn:5531 fp:71 fn:840 tp:4762
auc: 0.9186897536594074
alt auc: 0.9857839603364994
FPR: 0.01267404498393431
FNR: 0.149946447697251
Subject: 14
              precision    recall  f1-score   support

           0     0.8722    0.9794    0.9227      6068
           1     0.9765    0.8565    0.9126      6068

    accuracy                         0.9179     12136
   macro avg     0.9243    0.9179    0.9176     12136
weighted avg     0.9243    0.9179    0.9176     12136

0.02059986816084377
tn:5943 fp:125 fn:871 tp:5197
auc: 0.9179301252471984
alt auc: 0.981832043367869
FPR: 0.02059986816084377
FNR: 0.1435398813447594
Subject: 15
              precision    recall  f1-score   support

           0     0.8629    0.9794    0.9175      5918
           1     0.9762    0.8444    0.9055      5918

    accuracy                         0.9119     11836
   macro avg     0.9195    0.9119    0.9115     11836
weighted avg     0.9195    0.9119    0.9115     11836

0.020615072659682324
tn:5796 fp:122 fn:921 tp:4997
auc: 0.9118790131801284
alt auc: 0.9809511533140597
FPR: 0.020615072659682324
FNR: 0.15562690098006082
Subject: 16
              precision    recall  f1-score   support

           0     0.9100    0.9920    0.9492      9086
           1     0.9912    0.9019    0.9445      9086

    accuracy                         0.9470     18172
   macro avg     0.9506    0.9470    0.9468     18172
weighted avg     0.9506    0.9470    0.9468     18172

0.00803433854281312
tn:9013 fp:73 fn:891 tp:8195
auc: 0.9469513537310148
alt auc: 0.9936635335139087
FPR: 0.00803433854281312
FNR: 0.09806295399515738
Subject: 17
              precision    recall  f1-score   support

           0     0.8927    0.9904    0.9390      8326
           1     0.9892    0.8810    0.9320      8326

    accuracy                         0.9357     16652
   macro avg     0.9410    0.9357    0.9355     16652
weighted avg     0.9410    0.9357    0.9355     16652

0.009608455440787894
tn:8246 fp:80 fn:991 tp:7335
auc: 0.9356834013932259
alt auc: 0.9902455885897341
FPR: 0.009608455440787894
FNR: 0.11902474177276003
Subject: 18
              precision    recall  f1-score   support

           0     0.8953    0.9923    0.9413      7676
           1     0.9914    0.8839    0.9346      7676

    accuracy                         0.9381     15352
   macro avg     0.9433    0.9381    0.9379     15352
weighted avg     0.9433    0.9381    0.9379     15352

0.007686294945284002
tn:7617 fp:59 fn:891 tp:6785
auc: 0.9381188118811881
alt auc: 0.9919453981889235
FPR: 0.007686294945284002
FNR: 0.11607608129233976
Subject: 19
              precision    recall  f1-score   support

           0     0.9233    0.9882    0.9546     12352
           1     0.9873    0.9179    0.9513     12352

    accuracy                         0.9530     24704
   macro avg     0.9553    0.9530    0.9530     24704
weighted avg     0.9553    0.9530    0.9530     24704

0.011819948186528498
tn:12206 fp:146 fn:1014 tp:11338
auc: 0.9530440414507771
alt auc: 0.9914083952180345
FPR: 0.011819948186528498
FNR: 0.0820919689119171
Subject: 21
              precision    recall  f1-score   support

           0     0.9353    0.9932    0.9634      7252
           1     0.9928    0.9313    0.9611      7252

    accuracy                         0.9623     14504
   macro avg     0.9641    0.9623    0.9623     14504
weighted avg     0.9641    0.9623    0.9623     14504

0.006756756756756757
tn:7203 fp:49 fn:498 tp:6754
auc: 0.9622862658576944
alt auc: 0.993673807084886
FPR: 0.006756756756756757
FNR: 0.06867071152785438
Subject: 22
              precision    recall  f1-score   support

           0     0.9040    0.9905    0.9453     12079
           1     0.9895    0.8949    0.9398     12079

    accuracy                         0.9427     24158
   macro avg     0.9468    0.9427    0.9425     24158
weighted avg     0.9468    0.9427    0.9425     24158

0.0095206556834175
tn:11964 fp:115 fn:1270 tp:10809
auc: 0.9426690951237685
alt auc: 0.9899298051220474
FPR: 0.0095206556834175
FNR: 0.10514115406904545
Subject: 23
              precision    recall  f1-score   support

           0     0.9479    0.9893    0.9681     11552
           1     0.9888    0.9456    0.9667     11552

    accuracy                         0.9675     23104
   macro avg     0.9683    0.9675    0.9674     23104
weighted avg     0.9683    0.9675    0.9674     23104

0.010734072022160665
tn:11428 fp:124 fn:628 tp:10924
auc: 0.9674515235457063
alt auc: 0.9936941500758223
FPR: 0.010734072022160665
FNR: 0.054362880886426594
Subject: 24
              precision    recall  f1-score   support

           0     0.8907    0.9844    0.9352      8258
           1     0.9825    0.8791    0.9280      8258

    accuracy                         0.9318     16516
   macro avg     0.9366    0.9318    0.9316     16516
weighted avg     0.9366    0.9318    0.9316     16516

0.015621215790748365
tn:8129 fp:129 fn:998 tp:7260
auc: 0.9317631387745218
alt auc: 0.9891314870786476
FPR: 0.015621215790748365
FNR: 0.12085250666020829
Subject: 25
              precision    recall  f1-score   support

           0     0.9078    0.9918    0.9479      7404
           1     0.9909    0.8992    0.9429      7404

    accuracy                         0.9455     14808
   macro avg     0.9493    0.9455    0.9454     14808
weighted avg     0.9493    0.9455    0.9454     14808

0.008238789843327932
tn:7343 fp:61 fn:746 tp:6658
auc: 0.9455024311183146
alt auc: 0.9901288628425478
FPR: 0.008238789843327932
FNR: 0.10075634792004322
