Hello from compute69.bgsc.cluster
Done with train
Subject: 1
              precision    recall  f1-score   support

           0     0.9863    0.9957    0.9910     11997
           1     0.9957    0.9862    0.9909     11997

    accuracy                         0.9910     23994
   macro avg     0.9910    0.9910    0.9910     23994
weighted avg     0.9910    0.9910    0.9910     23994

0.0042510627656914225
tn:11946 fp:51 fn:166 tp:11831
auc: 0.9909560723514211
alt auc: 0.9994918779151597
FPR: 0.0042510627656914225
FNR: 0.0138367925314662
Subject: 2
              precision    recall  f1-score   support

           0     0.8482    0.9862    0.9120     11141
           1     0.9835    0.8234    0.8964     11141

    accuracy                         0.9048     22282
   macro avg     0.9158    0.9048    0.9042     22282
weighted avg     0.9158    0.9048    0.9042     22282

0.013822816623283368
tn:10987 fp:154 fn:1967 tp:9174
auc: 0.9048110582532988
alt auc: 0.970701024100658
FPR: 0.013822816623283368
FNR: 0.17655506687011938
Subject: 3
              precision    recall  f1-score   support

           0     0.8349    0.9817    0.9023     11342
           1     0.9777    0.8059    0.8835     11342

    accuracy                         0.8938     22684
   macro avg     0.9063    0.8938    0.8929     22684
weighted avg     0.9063    0.8938    0.8929     22684

0.018338917298536414
tn:11134 fp:208 fn:2202 tp:9140
auc: 0.8937577146887674
alt auc: 0.9738662017489235
FPR: 0.018338917298536414
FNR: 0.19414565332392877
Subject: 4
              precision    recall  f1-score   support

           0     0.8848    0.9853    0.9324     12406
           1     0.9835    0.8718    0.9242     12406

    accuracy                         0.9285     24812
   macro avg     0.9341    0.9285    0.9283     24812
weighted avg     0.9341    0.9285    0.9283     24812

0.014670320812510075
tn:12224 fp:182 fn:1591 tp:10815
auc: 0.9285426406577463
alt auc: 0.9758432062990847
FPR: 0.014670320812510075
FNR: 0.12824439787199743
Subject: 5
              precision    recall  f1-score   support

           0     0.8535    0.9855    0.9147     10473
           1     0.9828    0.8308    0.9004     10473

    accuracy                         0.9081     20946
   macro avg     0.9181    0.9081    0.9076     20946
weighted avg     0.9181    0.9081    0.9076     20946

0.014513510932875012
tn:10321 fp:152 fn:1772 tp:8701
auc: 0.9081447531748306
alt auc: 0.9798542361738998
FPR: 0.014513510932875012
FNR: 0.16919698271746395
Subject: 6
              precision    recall  f1-score   support

           0     0.8609    0.9747    0.9142     11375
           1     0.9708    0.8425    0.9021     11375

    accuracy                         0.9086     22750
   macro avg     0.9158    0.9086    0.9082     22750
weighted avg     0.9158    0.9086    0.9082     22750

0.02531868131868132
tn:11087 fp:288 fn:1792 tp:9583
auc: 0.9085714285714287
alt auc: 0.9751988754981281
FPR: 0.02531868131868132
FNR: 0.15753846153846154
Subject: 7
              precision    recall  f1-score   support

           0     0.8437    0.9891    0.9107     11742
           1     0.9868    0.8168    0.8938     11742

    accuracy                         0.9030     23484
   macro avg     0.9153    0.9030    0.9022     23484
weighted avg     0.9153    0.9030    0.9022     23484

0.01090103900528019
tn:11614 fp:128 fn:2151 tp:9591
auc: 0.9029552035428378
alt auc: 0.9752425726619162
FPR: 0.01090103900528019
FNR: 0.18318855390904445
Subject: 8
              precision    recall  f1-score   support

           0     0.8553    0.9858    0.9160     10304
           1     0.9833    0.8333    0.9021     10304

    accuracy                         0.9095     20608
   macro avg     0.9193    0.9095    0.9090     20608
weighted avg     0.9193    0.9095    0.9090     20608

0.014169254658385094
tn:10158 fp:146 fn:1718 tp:8586
auc: 0.9095496894409937
alt auc: 0.9799963109062151
FPR: 0.014169254658385094
FNR: 0.16673136645962733
Subject: 9
              precision    recall  f1-score   support

           0     0.8397    0.9865    0.9072     10778
           1     0.9836    0.8117    0.8894     10778

    accuracy                         0.8991     21556
   macro avg     0.9117    0.8991    0.8983     21556
weighted avg     0.9117    0.8991    0.8983     21556

0.013546112451289664
tn:10632 fp:146 fn:2029 tp:8749
auc: 0.8991000185563184
alt auc: 0.9763189835613882
FPR: 0.013546112451289664
FNR: 0.18825385043607348
Subject: 10
              precision    recall  f1-score   support

           0     0.8337    0.9865    0.9037     11847
           1     0.9835    0.8032    0.8842     11847

    accuracy                         0.8948     23694
   macro avg     0.9086    0.8948    0.8939     23694
weighted avg     0.9086    0.8948    0.8939     23694

0.013505528825863087
tn:11687 fp:160 fn:2332 tp:9515
auc: 0.8948256942685912
alt auc: 0.9769831772761184
FPR: 0.013505528825863087
FNR: 0.1968430826369545
Subject: 11
              precision    recall  f1-score   support

           0     0.8471    0.9910    0.9134     10742
           1     0.9891    0.8211    0.8973     10742

    accuracy                         0.9060     21484
   macro avg     0.9181    0.9060    0.9053     21484
weighted avg     0.9181    0.9060    0.9053     21484

0.009029975795941166
tn:10645 fp:97 fn:1922 tp:8820
auc: 0.9060230869484268
alt auc: 0.9791672783573535
FPR: 0.009029975795941166
FNR: 0.17892385030720537
Subject: 12
              precision    recall  f1-score   support

           0     0.8732    0.9720    0.9199      9860
           1     0.9684    0.8588    0.9103      9860

    accuracy                         0.9154     19720
   macro avg     0.9208    0.9154    0.9151     19720
weighted avg     0.9208    0.9154    0.9151     19720

0.027991886409736308
tn:9584 fp:276 fn:1392 tp:8468
auc: 0.9154158215010143
alt auc: 0.9778916802784623
FPR: 0.027991886409736308
FNR: 0.1411764705882353
Subject: 13
              precision    recall  f1-score   support

           0     0.8801    0.9747    0.9250     11053
           1     0.9716    0.8672    0.9164     11053

    accuracy                         0.9209     22106
   macro avg     0.9258    0.9209    0.9207     22106
weighted avg     0.9258    0.9209    0.9207     22106

0.0253324889170361
tn:10773 fp:280 fn:1468 tp:9585
auc: 0.920926445308966
alt auc: 0.976606864523006
FPR: 0.0253324889170361
FNR: 0.13281462046503212
Subject: 14
              precision    recall  f1-score   support

           0     0.8739    0.9841    0.9257     11867
           1     0.9818    0.8580    0.9157     11867

    accuracy                         0.9210     23734
   macro avg     0.9278    0.9210    0.9207     23734
weighted avg     0.9278    0.9210    0.9207     23734

0.01592651891800792
tn:11678 fp:189 fn:1685 tp:10182
auc: 0.9210415437768603
alt auc: 0.9832965951261917
FPR: 0.01592651891800792
FNR: 0.14199039352827167
Subject: 15
              precision    recall  f1-score   support

           0     0.8701    0.9853    0.9241     12118
           1     0.9831    0.8529    0.9133     12118

    accuracy                         0.9191     24236
   macro avg     0.9266    0.9191    0.9187     24236
weighted avg     0.9266    0.9191    0.9187     24236

0.01468889255652748
tn:11940 fp:178 fn:1783 tp:10335
auc: 0.9190873081366561
alt auc: 0.9841617973679679
FPR: 0.01468889255652748
FNR: 0.1471364911701601
Subject: 16
              precision    recall  f1-score   support

           0     0.9363    0.9949    0.9647     16548
           1     0.9946    0.9323    0.9624     16548

    accuracy                         0.9636     33096
   macro avg     0.9654    0.9636    0.9636     33096
weighted avg     0.9654    0.9636    0.9636     33096

0.005076142131979695
tn:16464 fp:84 fn:1121 tp:15427
auc: 0.9635907662557408
alt auc: 0.9960095101195932
FPR: 0.005076142131979695
FNR: 0.06774232535653855
Subject: 17
              precision    recall  f1-score   support

           0     0.9086    0.9962    0.9504     14540
           1     0.9958    0.8998    0.9454     14540

    accuracy                         0.9480     29080
   macro avg     0.9522    0.9480    0.9479     29080
weighted avg     0.9522    0.9480    0.9479     29080

0.003782668500687758
tn:14485 fp:55 fn:1457 tp:13083
auc: 0.9480055020632737
alt auc: 0.9921718652145861
FPR: 0.003782668500687758
FNR: 0.10020632737276479
Subject: 18
              precision    recall  f1-score   support

           0     0.8892    0.9969    0.9400     12055
           1     0.9965    0.8758    0.9323     12055

    accuracy                         0.9364     24110
   macro avg     0.9429    0.9364    0.9361     24110
weighted avg     0.9429    0.9364    0.9361     24110

0.0030692658647863955
tn:12018 fp:37 fn:1497 tp:10558
auc: 0.9363749481542928
alt auc: 0.9903114458290418
FPR: 0.0030692658647863955
FNR: 0.12418083782662795
Subject: 19
              precision    recall  f1-score   support

           0     0.8760    0.9963    0.9323     13907
           1     0.9957    0.8589    0.9223     13907

    accuracy                         0.9276     27814
   macro avg     0.9359    0.9276    0.9273     27814
weighted avg     0.9359    0.9276    0.9273     27814

0.003667217947796074
tn:13856 fp:51 fn:1962 tp:11945
auc: 0.9276263752067304
alt auc: 0.990740176054403
FPR: 0.003667217947796074
FNR: 0.14108003163874308
Subject: 20
              precision    recall  f1-score   support

           0     0.8877    0.9970    0.9392     14138
           1     0.9966    0.8739    0.9312     14138

    accuracy                         0.9355     28276
   macro avg     0.9422    0.9355    0.9352     28276
weighted avg     0.9422    0.9355    0.9352     28276

0.0029707172160135806
tn:14096 fp:42 fn:1783 tp:12355
auc: 0.9354576319139907
alt auc: 0.991392208835883
FPR: 0.0029707172160135806
FNR: 0.1261140189560051
Subject: 21
              precision    recall  f1-score   support

           0     0.9185    0.9963    0.9558     13083
           1     0.9959    0.9116    0.9519     13083

    accuracy                         0.9539     26166
   macro avg     0.9572    0.9539    0.9539     26166
weighted avg     0.9572    0.9539    0.9539     26166

0.003745318352059925
tn:13034 fp:49 fn:1156 tp:11927
auc: 0.9539478712833448
alt auc: 0.994020642866774
FPR: 0.003745318352059925
FNR: 0.08835893908125048
Subject: 22
              precision    recall  f1-score   support

           0     0.9204    0.9955    0.9565     13880
           1     0.9951    0.9139    0.9528     13880

    accuracy                         0.9547     27760
   macro avg     0.9578    0.9547    0.9546     27760
weighted avg     0.9578    0.9547    0.9546     27760

0.0044668587896253605
tn:13818 fp:62 fn:1195 tp:12685
auc: 0.9547190201729105
alt auc: 0.9896253161100915
FPR: 0.0044668587896253605
FNR: 0.08609510086455331
Subject: 23
              precision    recall  f1-score   support

           0     0.9058    0.9929    0.9474     12405
           1     0.9922    0.8967    0.9420     12405

    accuracy                         0.9448     24810
   macro avg     0.9490    0.9448    0.9447     24810
weighted avg     0.9490    0.9448    0.9447     24810

0.00709391374445788
tn:12317 fp:88 fn:1281 tp:11124
auc: 0.9448206368399839
alt auc: 0.9924300719324181
FPR: 0.00709391374445788
FNR: 0.10326481257557436
Subject: 24
              precision    recall  f1-score   support

           0     0.8851    0.9964    0.9375     13831
           1     0.9959    0.8707    0.9291     13831

    accuracy                         0.9335     27662
   macro avg     0.9405    0.9335    0.9333     27662
weighted avg     0.9405    0.9335    0.9333     27662

0.003615067601764153
tn:13781 fp:50 fn:1789 tp:12042
auc: 0.9335189068035573
alt auc: 0.9896470564361061
FPR: 0.003615067601764153
FNR: 0.1293471187911214
Subject: 25
              precision    recall  f1-score   support

           0     0.9057    0.9950    0.9483     12255
           1     0.9945    0.8965    0.9429     12255

    accuracy                         0.9457     24510
   macro avg     0.9501    0.9457    0.9456     24510
weighted avg     0.9501    0.9457    0.9456     24510

0.004977560179518564
tn:12194 fp:61 fn:1269 tp:10986
auc: 0.9457364341085271
alt auc: 0.988099565852188
FPR: 0.004977560179518564
FNR: 0.10354957160342718
